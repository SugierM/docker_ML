{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\48694\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Charts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch - ML\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27162</th>\n",
       "      <td>27163</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27163</th>\n",
       "      <td>27164</td>\n",
       "      <td>0</td>\n",
       "      <td>how to create the life you want  #success #lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27164</th>\n",
       "      <td>27165</td>\n",
       "      <td>0</td>\n",
       "      <td>be   being you! thank you @user for this inspi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27165</th>\n",
       "      <td>27166</td>\n",
       "      <td>0</td>\n",
       "      <td>maggie is just as   as me for my #allages #cdr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27166</th>\n",
       "      <td>27167</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user aww shame not elveden! we are goin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27167 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "27162  27163      0  #model   i love u take with u all the time in ...\n",
       "27163  27164      0  how to create the life you want  #success #lif...\n",
       "27164  27165      0  be   being you! thank you @user for this inspi...\n",
       "27165  27166      0  maggie is just as   as me for my #allages #cdr...\n",
       "27166  27167      0  @user @user aww shame not elveden! we are goin...\n",
       "\n",
       "[27167 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "split_part = int(len(_train_df) * 0.85)\n",
    "val_df = _train_df[split_part:]\n",
    "train_df = _train_df[:split_part]\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    25265\n",
       "1     1902\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n",
      "Sequence length: 100\n"
     ]
    }
   ],
   "source": [
    "# Load word vectors\n",
    "words = dict()\n",
    "\n",
    "def load_embedding(dictionary: dict, filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for lines in f.readlines():\n",
    "            line = lines.split(' ')\n",
    "            # print(f'WORD: {line[0]}')\n",
    "            # print(f'EMB: {line[1:]} \\nTYPE: {type(line[1:])}')\n",
    "            # break\n",
    "            try:\n",
    "                dictionary[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "load_embedding(words, 'glove.6B.100d.txt')\n",
    "VEC_DIM = words['the'].shape[0]\n",
    "print(len(words))\n",
    "print(f'Sequence length: {VEC_DIM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS: ['bihday', 'your', 'majesty']\n",
      "STANDARD TOKENS: ['your', 'majesty']\n"
     ]
    }
   ],
   "source": [
    "# Test sentence\n",
    "sentence_ = 'bihday your majesty'\n",
    "\n",
    "# Split sentence into words\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+') # Split on words\n",
    "print(f'TOKENS: {tokenizer.tokenize(sentence_)}')\n",
    "\n",
    "# Take stem of a word\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def to_tokens(sentences: str, vector_words: dict=words) -> list:\n",
    "    \"\"\"\n",
    "    Splits string into list of strings and standardized every word.\n",
    "    \"\"\"\n",
    "    t = tokenizer.tokenize(sentences)\n",
    "    t_lower = [s.lower() for s in t]\n",
    "    t_lem = [lemmatizer.lemmatize(s) for s in t_lower]\n",
    "    t = [s for s in t_lem if s in words]\n",
    "    return t\n",
    "\n",
    "print(f'STANDARD TOKENS: {to_tokens(sentence_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 100])\n",
      "tensor([[[-0.5718,  0.0463,  0.8673, -0.5903, -0.6493,  0.6588, -0.8279,\n",
      "           0.2257, -0.0198,  0.2122,  0.3753,  0.1748,  0.2859,  0.2292,\n",
      "          -0.1048, -0.3686, -0.0976,  0.5299, -0.0240,  0.4108, -0.6807,\n",
      "          -0.1125, -0.3501, -0.2945,  0.3823,  0.9398, -0.7363, -1.0142,\n",
      "           0.6061, -0.4646,  0.8398,  1.2551,  0.4999,  0.0418, -0.3125,\n",
      "           0.3882, -0.6621,  0.0026,  0.6252, -0.7410,  0.5719, -0.3599,\n",
      "           0.2182, -0.7801, -0.7755,  0.1330, -0.9260, -0.3226, -0.0252,\n",
      "          -1.3961,  0.2293,  0.2695, -0.1612,  0.8521, -0.0786, -2.2859,\n",
      "           0.8719,  0.2970,  2.3800, -0.1992,  0.5504,  1.6426, -0.3106,\n",
      "          -0.0293,  0.9394,  0.5702,  0.5862, -0.2594,  0.3897, -0.5606,\n",
      "           0.0991,  0.4679,  0.5448, -0.9599,  0.6297,  0.4391, -0.2858,\n",
      "          -0.4836, -0.4151,  0.1803,  0.4332,  0.5131, -0.3704, -0.1585,\n",
      "          -1.5992, -0.2138, -0.1418, -0.1423, -0.1247, -0.0529, -0.6274,\n",
      "           0.8598,  1.2702,  0.0453, -0.5447, -0.5543,  0.2564, -0.3566,\n",
      "           0.9293,  0.8995],\n",
      "         [ 0.1401, -0.5746,  0.9515,  0.3164,  0.2120,  0.4819, -0.8559,\n",
      "           0.4060, -0.5954,  0.1494,  0.1006,  0.2496,  0.0456,  0.7340,\n",
      "          -0.3193, -0.6883,  0.1727, -0.2684, -0.3988,  0.2807, -0.4250,\n",
      "          -0.6401, -0.2479, -0.8212,  0.2477,  0.5171,  0.0440, -0.0882,\n",
      "           1.0492, -0.5623,  0.5163, -0.1373,  0.3420, -0.3318, -0.3199,\n",
      "           1.1742, -0.6955,  0.2391,  0.0040, -1.2252,  0.3507,  0.4454,\n",
      "           0.2441,  0.2215,  0.6602, -0.0143, -0.1540, -0.1471,  0.8550,\n",
      "          -0.0886,  0.5870,  0.0945,  1.0862,  0.4286, -0.1908, -0.3628,\n",
      "           0.6910,  0.2413,  0.7104, -0.6114,  0.2430, -0.0040, -0.4443,\n",
      "           0.0765, -0.1440,  0.2444, -0.7377,  0.0060,  0.5153,  0.1682,\n",
      "           0.5822, -0.3538,  1.0233, -0.5726,  0.1130, -0.0580,  0.2315,\n",
      "           0.2753, -0.5415, -0.1289,  0.1512,  0.0103,  0.7440,  0.8684,\n",
      "          -0.3683, -0.4817,  0.2814, -0.6824,  0.3814, -0.6676, -0.2251,\n",
      "          -0.3726,  0.3537,  0.2601, -0.3324, -0.5221, -0.5136, -0.7168,\n",
      "          -0.4566, -0.0893]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48694\\AppData\\Local\\Temp\\ipykernel_16808\\3570375404.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return torch.tensor(vectors, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "# Word embed\n",
    "def embed(sentences: str, vector_words: dict=words) -> np.array:\n",
    "    \"\"\"\n",
    "    Transforms sequences into list of embedded words.\n",
    "    \"\"\"\n",
    "    tokens = to_tokens(sentences)\n",
    "    vectors = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in vector_words:\n",
    "            continue\n",
    "\n",
    "        token_vector = vector_words[token]\n",
    "        vectors.append(token_vector)\n",
    "\n",
    "    return torch.tensor(vectors, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "print(embed(sentence_).shape)\n",
    "print(embed(sentence_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into X and y for ML\n",
    "def transform_X_y(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Takes dataframe and splits it into arguments and targets for ML algorithm.\n",
    "    \"\"\"\n",
    "    y = df['label'].to_numpy().astype(int)\n",
    "\n",
    "    X = []\n",
    "    for message in df['tweet']:\n",
    "        vectorized_message = embed(message)\n",
    "\n",
    "        if vectorized_message.shape[0] == 0:\n",
    "            vectorized_message = np.zeros(shape=(1, VEC_DIM)) # for now it is as single word\n",
    "\n",
    "        X.append(vectorized_message)\n",
    "\n",
    "    return X, np.array(y)\n",
    "\n",
    "\n",
    "X, y = transform_X_y(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (27167, 57, 100)\n",
      "y: (27167,)\n"
     ]
    }
   ],
   "source": [
    "# Create padding to make sequences the same length\n",
    "def pad_X(ls: list, length: int):\n",
    "    ls_copy = deepcopy(ls)\n",
    "\n",
    "    for i, x in enumerate(ls):\n",
    "        x_len = x.shape[0]\n",
    "\n",
    "        if x_len > length:\n",
    "            ls_copy[i] = x[:length]\n",
    "        else:\n",
    "            seq_diff = length - x_len\n",
    "            paddding = np.zeros(shape=(seq_diff, VEC_DIM))\n",
    "            ls_copy[i] = np.concatenate([x, paddding])\n",
    "        \n",
    "    return np.array(ls_copy).astype(float)\n",
    "\n",
    "X = pad_X(X, 57)\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "X_val, y_val = transform_X_y(val_df)\n",
    "X_val = pad_X(X_val, 57)\n",
    "\n",
    "# # Test ---- Test do not have label column\n",
    "# X_test, y_val = transform_X_y(test_df)\n",
    "# X_test = pad_X(X_test, 57)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "tensor([[0.5039]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Sentiment(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden, layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=hidden,\n",
    "                            num_layers=layers,\n",
    "                            dropout=dropout)\n",
    "        self.linear = nn.Linear(in_features=hidden, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = embed(x)\n",
    "        out, hidden = self.lstm(out)\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return self.sigmoid(out)\n",
    "        \n",
    "model = Sentiment(100, 64, 4, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
