{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\48694\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Pytorch - ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    29720\n",
       "1     2242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# Load word vectors\n",
    "words = dict()\n",
    "\n",
    "def load_embedding(dictionary: dict, filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for lines in f.readlines():\n",
    "            line = lines.split(' ')\n",
    "            # print(f'WORD: {line[0]}')\n",
    "            # print(f'EMB: {line[1:]} \\nTYPE: {type(line[1:])}')\n",
    "            # break\n",
    "            try:\n",
    "                dictionary[line[0]] = np.array(line[1:], dtype=float)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "load_embedding(words, 'glove.6B.100d.txt')   \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS: ['bihday', 'your', 'majesty']\n",
      "STANDARD TOKENS: ['your', 'majesty']\n"
     ]
    }
   ],
   "source": [
    "# Test sentence\n",
    "sentence_ = 'bihday your majesty'\n",
    "\n",
    "# Split sentence into words\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+') # Split on words\n",
    "print(f'TOKENS: {tokenizer.tokenize(sentence_)}')\n",
    "\n",
    "# Take stem of a word\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def to_tokens(sentences: str, vector_words: dict=words) -> list:\n",
    "    t = tokenizer.tokenize(sentences)\n",
    "    t_lower = [s.lower() for s in t]\n",
    "    t_lem = [lemmatizer.lemmatize(s) for s in t_lower]\n",
    "    t = [s for s in t_lem if s in words]\n",
    "    return t\n",
    "\n",
    "print(f'STANDARD TOKENS: {to_tokens(sentence_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "[[-2.9163e-02  8.1769e-01  3.8470e-01 -7.7857e-01  1.1049e+00 -1.3655e-01\n",
      "  -2.4691e-02 -5.1103e-02  7.7950e-01  5.1357e-02 -3.5748e-01  1.1748e+00\n",
      "  -9.8244e-02  3.3111e-01  4.0426e-01  5.8685e-01 -6.2536e-01  9.4833e-02\n",
      "   9.7024e-01 -1.1437e+00  1.3826e-01  2.8136e-01  4.6693e-01  3.5226e-01\n",
      "   6.8916e-01 -1.9819e+00 -1.4000e+00  1.7001e-01  1.5929e+00 -1.0086e+00\n",
      "   3.6499e+00  1.3949e+00 -7.8823e-01  4.0404e-01 -3.6925e-01  7.3075e-01\n",
      "   2.7513e-02 -1.1993e-01  7.3716e-01 -1.0365e+00  6.8659e-01 -3.0294e-01\n",
      "  -5.5175e-01  9.6466e-01  5.3103e-02 -8.4807e-02  8.5120e-01 -5.4186e-01\n",
      "   3.2453e-01  5.8425e-01]\n",
      " [ 1.6999e-01  9.4964e-01 -1.1559e+00 -6.6555e-01  6.5813e-01 -1.0987e+00\n",
      "   8.3952e-01  6.2359e-01  3.4939e-01 -6.4611e-01  2.7352e-01  1.7612e+00\n",
      "   4.6555e-01 -1.6568e-01 -4.8375e-02  3.3241e-01 -7.8166e-01  4.0905e-01\n",
      "   2.1636e-01  1.8103e-01  8.2853e-01  5.2009e-01  3.6097e-02 -5.1258e-01\n",
      "   3.1427e-01 -1.2165e+00 -1.0347e+00  3.7987e-02 -8.5888e-02  6.2726e-01\n",
      "   7.3276e-01  3.4852e-01 -2.3125e-01  3.7887e-01 -2.1147e-03  4.5607e-01\n",
      "   6.0021e-01 -3.3157e-01 -1.0273e+00 -3.5612e-01  6.1704e-01  1.2959e-01\n",
      "  -1.6071e-02 -1.5090e-01 -1.1741e+00 -1.0922e-01 -7.8031e-01 -8.6858e-01\n",
      "  -8.0147e-02 -2.6119e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Word embed\n",
    "def embed(sentences: str, vector_words: dict=words) -> np.array:\n",
    "    tokens = to_tokens(sentences)\n",
    "    vectors = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in vector_words:\n",
    "            continue\n",
    "\n",
    "        token_vector = vector_words[token]\n",
    "        vectors.append(token_vector)\n",
    "\n",
    "    return np.array(vectors, dtype=float)\n",
    "\n",
    "print(embed(sentence_).shape)\n",
    "print(embed(sentence_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
